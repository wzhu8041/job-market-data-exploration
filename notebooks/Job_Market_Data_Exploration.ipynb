{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load data from dirctory:"
      ],
      "metadata": {
        "id": "TDvmvnN-IkFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "DATA_DIR = Path('data')\n",
        "print(f\"Path to data directory: {DATA_DIR}\")"
      ],
      "metadata": {
        "id": "A4HEhJj8qzbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generic BLS flat-file loader to read in the data"
      ],
      "metadata": {
        "id": "p1wYFIKDI58b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_bls_tsv(path: str | Path):\n",
        "    df = pd.read_csv(path, sep=\"\\t\", dtype={\"series_id\": \"string\", \"period\": \"string\"})\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "    df[\"series_id\"] = df[\"series_id\"].astype(\"string\").str.strip()\n",
        "    df[\"period\"] = df[\"period\"].astype(\"string\").str.strip()\n",
        "    df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
        "\n",
        "    # Keep monthly only (drop M13 annual)\n",
        "    df = df[df[\"period\"].str.match(r\"^M(0[1-9]|1[0-2])$\")].copy()\n",
        "    df[\"month\"] = df[\"period\"].str[1:3].astype(int)\n",
        "    df[\"date\"] = pd.to_datetime(df[\"year\"].astype(str) + \"-\" + df[\"month\"].astype(str).str.zfill(2) + \"-01\")\n",
        "\n",
        "    # Keep only the columns we need for plotting/merging\n",
        "    keep_cols = [\"series_id\", \"date\", \"value\"]\n",
        "    if \"footnote_codes\" in df.columns:\n",
        "        df[\"footnote_codes\"] = df[\"footnote_codes\"].astype(\"string\").str.strip()\n",
        "        keep_cols.append(\"footnote_codes\")\n",
        "\n",
        "    return df[keep_cols]"
      ],
      "metadata": {
        "id": "AqXW7smFq3l3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Small helper for metadata(\"lookup\") files"
      ],
      "metadata": {
        "id": "51FmYfhnJCuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_meta_tsv(path: str | Path):\n",
        "    df = pd.read_csv(path, sep=\"\\t\", dtype=\"string\")\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    for c in df.columns:\n",
        "        df[c] = df[c].astype(\"string\").str.strip()\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "A71bwvJ0q5Jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter-Load a big BLS data file by series_id (loads in chunks)"
      ],
      "metadata": {
        "id": "NG3SkpDXJKup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_bls_tsv_filtered(path: str | Path, keep_series_ids: set[str], chunksize: int = 2_000_000):\n",
        "    chunks = pd.read_csv(path, sep=\"\\t\", dtype={\"series_id\": \"string\", \"period\": \"string\"}, chunksize=chunksize)\n",
        "    out = []\n",
        "    for c in chunks:\n",
        "        c.columns = [x.strip() for x in c.columns]\n",
        "        c[\"series_id\"] = c[\"series_id\"].astype(\"string\").str.strip()\n",
        "        c[\"period\"] = c[\"period\"].astype(\"string\").str.strip()\n",
        "        c = c[c[\"series_id\"].isin(keep_series_ids)]\n",
        "        if len(c):\n",
        "            # Reuse the same logic to build date + value\n",
        "            c[\"value\"] = pd.to_numeric(c[\"value\"], errors=\"coerce\")\n",
        "            c = c[c[\"period\"].str.match(r\"^M(0[1-9]|1[0-2])$\")].copy()\n",
        "            c[\"month\"] = c[\"period\"].str[1:3].astype(int)\n",
        "            c[\"date\"] = pd.to_datetime(c[\"year\"].astype(str) + \"-\" + c[\"month\"].astype(str).str.zfill(2) + \"-01\")\n",
        "            keep_cols = [\"series_id\", \"date\", \"value\"]\n",
        "            if \"footnote_codes\" in c.columns:\n",
        "                c[\"footnote_codes\"] = c[\"footnote_codes\"].astype(\"string\").str.strip()\n",
        "                keep_cols.append(\"footnote_codes\")\n",
        "            out.append(c[keep_cols])\n",
        "\n",
        "    return pd.concat(out, ignore_index=True) if out else pd.DataFrame(columns=[\"series_id\", \"date\", \"value\"])"
      ],
      "metadata": {
        "id": "wHSRA9Ejq7R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading all files (from Bureau of Labor Statistics)"
      ],
      "metadata": {
        "id": "p9jkVEMLJRGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- JOLTS metadata (for mapping + drill-down) ----\n",
        "jt_series     = read_meta_tsv(DATA_DIR / \"jt.series.txt\")\n",
        "jt_industry   = read_meta_tsv(DATA_DIR / \"jt.industry.txt\")\n",
        "jt_ratelevel  = read_meta_tsv(DATA_DIR / \"jt.ratelevel.txt\")\n",
        "jt_period     = read_meta_tsv(DATA_DIR / \"jt.period.txt\")\n",
        "jt_dataelem   = read_meta_tsv(DATA_DIR / \"jt.dataelement.txt\")"
      ],
      "metadata": {
        "id": "bTA8JQuMkoix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- JOLTS data (openings / hires / quits) ----\n",
        "jt_openings = read_bls_tsv(DATA_DIR / \"jt.data.2.JobOpenings.txt\")\n",
        "jt_hires    = read_bls_tsv(DATA_DIR / \"jt.data.3.Hires.txt\")\n",
        "jt_quits    = read_bls_tsv(DATA_DIR / \"jt.data.5.Quits.txt\")"
      ],
      "metadata": {
        "id": "Mlit8yn8krnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- CES metadata (for series discovery & labels) ----\n",
        "ce_series    = read_meta_tsv(DATA_DIR / \"ce.series.txt\")\n",
        "ce_datatype  = read_meta_tsv(DATA_DIR / \"ce.datatype.txt\")\n",
        "ce_industry  = read_meta_tsv(DATA_DIR / \"ce.industry.txt\")"
      ],
      "metadata": {
        "id": "uycYrJ0Lktm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- CES data (employment + earnings by industry) ----\n",
        "ce_fin_emp  = read_bls_tsv(DATA_DIR / \"ce.data.55a.FinancialActivities.Employment.txt\")\n",
        "ce_fin_ae   = read_bls_tsv(DATA_DIR / \"ce.data.55b.FinancialActivities.AllEmployeeHoursAndEarnings.txt\")\n",
        "\n",
        "ce_pbs_emp  = read_bls_tsv(DATA_DIR / \"ce.data.60a.ProfessionalBusinessServices.Employment.txt\")\n",
        "ce_pbs_ae   = read_bls_tsv(DATA_DIR / \"ce.data.60b.ProfessionalBusinessServices.AllEmployeeHoursAndEarnings.txt\")"
      ],
      "metadata": {
        "id": "1fSCnwdpkvjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Unemployment Rate"
      ],
      "metadata": {
        "id": "cNh9KqQ9JfM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LN_PATH = DATA_DIR / \"ln.data.1.AllData.txt\"\n",
        "UR_ID = \"LNS14000000\"  # headline unemployment rate (U-3)\n",
        "\n",
        "ln_ur_raw = read_bls_tsv_filtered(LN_PATH, {UR_ID})\n",
        "ur = (\n",
        "    ln_ur_raw\n",
        "    .rename(columns={\"value\": \"ur\"})\n",
        "    [[\"date\", \"ur\"]]\n",
        "    .sort_values(\"date\")\n",
        "    .reset_index(drop=True)\n",
        ")"
      ],
      "metadata": {
        "id": "GXlaZzChkzEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bundle into Dictionaries"
      ],
      "metadata": {
        "id": "tmQoGvoJJkiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group into variables for convenience\n",
        "\n",
        "* `data[\"jt\"]` for Job Openings and Labor Turnover Survey (JOLTS)\n",
        "\n",
        "* `data[\"ce\"]` for Current Employment Statistics (CES)\n",
        "\n",
        "* `data[\"ur\"]` for unemployment data"
      ],
      "metadata": {
        "id": "vOQ9nXWxOrNv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBlK8VgHVL_j"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"jt\": {\n",
        "        \"series\": jt_series,\n",
        "        \"industry\": jt_industry,\n",
        "        \"ratelevel\": jt_ratelevel,\n",
        "        \"period\": jt_period,\n",
        "        \"dataelement\": jt_dataelem,\n",
        "        \"openings\": jt_openings,\n",
        "        \"hires\": jt_hires,\n",
        "        \"quits\": jt_quits,\n",
        "    },\n",
        "    \"ce\": {\n",
        "        \"series\": ce_series,\n",
        "        \"datatype\": ce_datatype,\n",
        "        \"industry\": ce_industry,\n",
        "        \"fin_emp\": ce_fin_emp,\n",
        "        \"fin_ae\": ce_fin_ae,\n",
        "        \"pbs_emp\": ce_pbs_emp,\n",
        "        \"pbs_ae\": ce_pbs_ae,  # None unless you set pbs_keep\n",
        "    },\n",
        "    \"ur\": ur\n",
        "}\n",
        "\n",
        "print(\"Loaded:\")\n",
        "print(\"  JOLTS openings rows:\", len(jt_openings))\n",
        "print(\"  JOLTS hires rows:\", len(jt_hires))\n",
        "print(\"  JOLTS quits rows:\", len(jt_quits))\n",
        "print(\"  CES fin emp rows:\", len(ce_fin_emp))\n",
        "print(\"  CES pbs emp rows:\", len(ce_pbs_emp))\n",
        "print(\"  Unemployment rate rows:\", len(ur))\n",
        "print(\"  PBS AE loaded?:\", ce_pbs_ae is not None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Vis 1: Unemployment vs Openings (Belridge Curve 2021-2025)"
      ],
      "metadata": {
        "id": "LjQNCixCLeej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions for plotting and series selection"
      ],
      "metadata": {
        "id": "1DmeCabWMI9C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use metadata to pick series, then use `series_ts()` to retrieve the actual time series."
      ],
      "metadata": {
        "id": "ENrXDwpaPHET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "def series_ts(df: pd.DataFrame, series_id: str, value_name: str = \"value\") -> pd.DataFrame:\n",
        "    \"\"\"Return a single-series time series with columns: date, <value_name>.\"\"\"\n",
        "    out = df[df[\"series_id\"] == series_id][[\"date\", \"value\"]].copy()\n",
        "    if out.empty:\n",
        "        raise KeyError(f\"series_id not found in dataframe: {series_id}\")\n",
        "    out = out.sort_values(\"date\").rename(columns={\"value\": value_name}).reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "def latest_yoy_pct(s: pd.Series) -> float:\n",
        "    \"\"\"Latest YoY percent change (needs monthly frequency).\"\"\"\n",
        "    yoy = (s / s.shift(12) - 1.0) * 100.0\n",
        "    yoy = yoy.dropna()\n",
        "    return float(yoy.iloc[-1]) if len(yoy) else float(\"nan\")\n",
        "\n",
        "def find_jolts_industry_code(jt_industry: pd.DataFrame, keyword: str) -> str:\n",
        "    \"\"\"Find the first JOLTS industry_code whose industry_text contains keyword.\"\"\"\n",
        "    m = jt_industry[jt_industry[\"industry_text\"].str.contains(keyword, case=False, na=False)]\n",
        "    if m.empty:\n",
        "        raise KeyError(f\"No JOLTS industry match for keyword: {keyword}\")\n",
        "    return m.iloc[0][\"industry_code\"]\n",
        "\n",
        "def pick_jolts_series_id(\n",
        "    jt_series: pd.DataFrame,\n",
        "    dataelement_code: str,\n",
        "    ratelevel_code: str,\n",
        "    industry_code: str,\n",
        "    state_code: str = \"00\",\n",
        "    area_code: str = \"00000\",\n",
        "    sizeclass_code: str = \"00\",\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Pick a JOLTS series_id from jt_series using metadata codes.\n",
        "    This is more robust than hardcoding series IDs.\n",
        "    \"\"\"\n",
        "    df = jt_series.copy()\n",
        "\n",
        "    # normalize whitespace just in case\n",
        "    for c in [\"dataelement_code\",\"ratelevel_code\",\"industry_code\",\"state_code\",\"area_code\",\"sizeclass_code\"]:\n",
        "        if c in df.columns:\n",
        "            df[c] = df[c].astype(\"string\").str.strip()\n",
        "\n",
        "    m = df[\n",
        "        (df[\"dataelement_code\"] == dataelement_code) &\n",
        "        (df[\"ratelevel_code\"] == ratelevel_code) &\n",
        "        (df[\"industry_code\"] == industry_code) &\n",
        "        (df[\"state_code\"] == state_code) &\n",
        "        (df[\"area_code\"] == area_code) &\n",
        "        (df[\"sizeclass_code\"] == sizeclass_code)\n",
        "    ]\n",
        "\n",
        "    if m.empty:\n",
        "        raise KeyError(\n",
        "            f\"No JOLTS series found for dataelement={dataelement_code}, ratelevel={ratelevel_code}, industry={industry_code}\"\n",
        "        )\n",
        "\n",
        "    # If multiple matches exist, just take the first.\n",
        "    return m.iloc[0][\"series_id\"]\n"
      ],
      "metadata": {
        "id": "OZcXNk6IlzAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###"
      ],
      "metadata": {
        "id": "4_LkCPj0MRXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Beveridge curve: unemployment vs job openings rate\n",
        "\n",
        "---\n",
        "\n",
        "### Industry openings rate over time (Business and Finance Sectors)"
      ],
      "metadata": {
        "id": "8w2C29_SPRDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Total nonfarm Job Openings Rate (JOR) ---\n",
        "try:\n",
        "    total_ind_code = \"000000\"\n",
        "    total_jor_id = pick_jolts_series_id(\n",
        "        jt_series,\n",
        "        dataelement_code=\"JO\",\n",
        "        ratelevel_code=\"R\",\n",
        "        industry_code=total_ind_code\n",
        "    )\n",
        "except Exception:\n",
        "    total_ind_code = find_jolts_industry_code(jt_industry, \"Total\")\n",
        "    total_jor_id = pick_jolts_series_id(jt_series, \"JO\", \"R\", total_ind_code)\n",
        "\n",
        "jor_total = series_ts(jt_openings, total_jor_id, value_name=\"jor\")\n",
        "\n",
        "# --- Window filter (2022–2025) ---\n",
        "start = pd.Timestamp(\"2023-01-01\")\n",
        "end   = pd.Timestamp(\"2026-1-01\")  # monthly data uses first-of-month dates\n",
        "\n",
        "def in_window(df):\n",
        "    return df[(df[\"date\"] >= start) & (df[\"date\"] <= end)].copy()\n",
        "\n",
        "# --- Beveridge curve data: merge job openings rate with unemployment rate ---\n",
        "bev = jor_total.merge(ur, on=\"date\", how=\"inner\").sort_values(\"date\")\n",
        "bev = in_window(bev)\n",
        "\n",
        "# tag last 6 months (within the window) for highlighting\n",
        "last_date = bev[\"date\"].max()\n",
        "bev[\"recent_6m\"] = bev[\"date\"] >= (last_date - pd.DateOffset(months=6))\n",
        "\n",
        "fig_bev = px.scatter(\n",
        "    bev,\n",
        "    x=\"ur\",\n",
        "    y=\"jor\",\n",
        "    color=bev[\"date\"].dt.year.astype(str),\n",
        "    symbol=\"recent_6m\",\n",
        "    hover_data=[\"date\"],\n",
        "    title=\"Beveridge Curve (2021–2025): Unemployment Rate vs Job Openings Rate\",\n",
        "    labels={\"ur\": \"Unemployment rate (%)\", \"jor\": \"Job openings rate (%)\", \"color\": \"Year\"},\n",
        ")\n",
        "fig_bev.show()\n",
        "\n",
        "# --- Industry drill-down for openings rate ---\n",
        "fin_code  = find_jolts_industry_code(jt_industry, \"Financial\")\n",
        "pbs_code  = find_jolts_industry_code(jt_industry, \"Professional\")\n",
        "\n",
        "industry_list = [\n",
        "    (\"Financial activities\", fin_code),\n",
        "    (\"Professional & business services\", pbs_code),\n",
        "]\n",
        "\n",
        "drill = []\n",
        "for name, code in industry_list:\n",
        "    sid = pick_jolts_series_id(jt_series, dataelement_code=\"JO\", ratelevel_code=\"R\", industry_code=code)\n",
        "    tmp = series_ts(jt_openings, sid, value_name=\"openings_rate\")\n",
        "    tmp[\"industry\"] = name\n",
        "    drill.append(tmp)\n",
        "\n",
        "drill_df = pd.concat(drill, ignore_index=True)\n",
        "drill_df = in_window(drill_df)\n",
        "\n",
        "\n",
        "\n",
        "fig_drill = px.line(\n",
        "    drill_df,\n",
        "    x=\"date\",\n",
        "    y=\"openings_rate\",\n",
        "    color=\"industry\",\n",
        "    title=\"Job Openings Rate by Industry (2021–2025, selected)\",\n",
        "    labels={\"openings_rate\": \"Job openings rate (%)\"},\n",
        ")\n",
        "fig_drill.show()\n"
      ],
      "metadata": {
        "id": "tAGWCDxLqn2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Vis 2: Job Hunt Index"
      ],
      "metadata": {
        "id": "woppaBNhP_vZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a homemade composite statistic determined by:\n",
        "\n",
        "$z(Job\\space Openings) + z(Hires \\space Rate)+ z(Quit\\space Rate) - z(Unemployment\\space Rate)$\n",
        "\n",
        "where $z(x)$ is the z-score of column x\n",
        "*   If the index rises: conditions “feel” more favorable for job seekers\n",
        "*   If it falls: conditions “feel” tougher"
      ],
      "metadata": {
        "id": "B_52JWwBQ0ZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Pull total rates for openings, hires, quits ---\n",
        "jor_id = pick_jolts_series_id(jt_series, dataelement_code=\"JO\", ratelevel_code=\"R\", industry_code=total_ind_code)\n",
        "hir_id = pick_jolts_series_id(jt_series, dataelement_code=\"HI\", ratelevel_code=\"R\", industry_code=total_ind_code)\n",
        "qur_id = pick_jolts_series_id(jt_series, dataelement_code=\"QU\", ratelevel_code=\"R\", industry_code=total_ind_code)\n",
        "\n",
        "jor_ts = series_ts(jt_openings, jor_id, value_name=\"jor\")\n",
        "hir_ts = series_ts(jt_hires,    hir_id, value_name=\"hir\")\n",
        "qur_ts = series_ts(jt_quits,    qur_id, value_name=\"qur\")\n",
        "\n",
        "df = (\n",
        "    jor_ts.merge(hir_ts, on=\"date\", how=\"inner\")\n",
        "          .merge(qur_ts, on=\"date\", how=\"inner\")\n",
        "          .merge(ur,     on=\"date\", how=\"inner\")\n",
        "          .sort_values(\"date\")\n",
        "          .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "# clean + drop missing components\n",
        "for col in [\"jor\", \"hir\", \"qur\", \"ur\"]:\n",
        "    df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "\n",
        "df = (df.dropna(subset=[\"jor\", \"hir\", \"qur\", \"ur\"])   # drops Oct 2025 UR missing, etc.\n",
        "        .sort_values(\"date\")\n",
        "        .reset_index(drop=True))\n",
        "# dropna(subset=...) is the standard way to remove rows with missing values in specific columns. :contentReference[oaicite:1]{index=1}\n",
        "\n",
        "# --- Window filter (2022–2025) ---\n",
        "start = pd.Timestamp(\"2022-01-01\")\n",
        "end   = pd.Timestamp(\"2025-12-01\")\n",
        "\n",
        "df = df[(df[\"date\"] >= start) & (df[\"date\"] <= end)].copy()\n",
        "df = df.sort_values(\"date\").reset_index(drop=True)\n",
        "\n",
        "def z(s: pd.Series) -> pd.Series:\n",
        "    sd = s.std(ddof=0)\n",
        "    if pd.isna(sd) or sd == 0:\n",
        "        return pd.Series(0.0, index=s.index)\n",
        "    return (s - s.mean()) / sd\n",
        "\n",
        "# compute z-scores\n",
        "df[\"z_jor\"] = z(df[\"jor\"])\n",
        "df[\"z_hir\"] = z(df[\"hir\"])\n",
        "df[\"z_qur\"] = z(df[\"qur\"])\n",
        "df[\"z_ur\"]  = z(df[\"ur\"])\n",
        "\n",
        "df[\"index\"] = df[\"z_jor\"] + df[\"z_hir\"] + df[\"z_qur\"] - df[\"z_ur\"]\n",
        "\n",
        "latest = df.iloc[-1]\n",
        "prev   = df.iloc[-2]\n",
        "\n",
        "index_level = float(latest[\"index\"])\n",
        "index_change = float(latest[\"index\"] - prev[\"index\"])\n",
        "\n",
        "# detect whether this is truly month-over-month\n",
        "gap = (latest[\"date\"].year - prev[\"date\"].year) * 12 + (latest[\"date\"].month - prev[\"date\"].month)\n",
        "change_label = \"MoM change\" if gap == 1 else f\"Change since previous available month ({prev['date']:%Y-%m}→{latest['date']:%Y-%m})\"\n",
        "\n",
        "print(f\"Job Hunt Index (latest): {index_level:.2f}\")\n",
        "print(f\"{change_label}: {index_change:+.2f}\")\n",
        "\n",
        "# --- 2B) Sparkline ---\n",
        "fig_idx = px.line(\n",
        "    df,\n",
        "    x=\"date\",\n",
        "    y=\"index\",\n",
        "    title=\"Job Hunt Index (2022–2025)\",\n",
        "    labels={\"index\": \"Index (z-scored composite)\"},\n",
        ")\n",
        "fig_idx.show()\n",
        "\n",
        "# contributions using z-columns + label the window correctly\n",
        "contrib = pd.Series({\n",
        "    \"Openings rate (JOR)\": df[\"z_jor\"].iloc[-1] - df[\"z_jor\"].iloc[-2],\n",
        "    \"Hires rate (HIR)\":    df[\"z_hir\"].iloc[-1] - df[\"z_hir\"].iloc[-2],\n",
        "    \"Quits rate (QUR)\":    df[\"z_qur\"].iloc[-1] - df[\"z_qur\"].iloc[-2],\n",
        "    \"Unemp rate (UR)\":    -(df[\"z_ur\"].iloc[-1]  - df[\"z_ur\"].iloc[-2]),  # minus because UR is subtracted in index\n",
        "}).sort_values()\n",
        "\n",
        "contrib_df = contrib.rename(\"contribution\").reset_index().rename(columns={\"index\": \"component\"})\n",
        "\n",
        "title_suffix = \"MoM contributions\" if gap == 1 else f\"Change contributions ({prev['date']:%Y-%m}→{latest['date']:%Y-%m})\"\n",
        "fig_contrib = px.bar(\n",
        "    contrib_df,\n",
        "    x=\"contribution\",\n",
        "    y=\"component\",\n",
        "    orientation=\"h\",\n",
        "    title=f\"What moved the index? ({title_suffix}, 2022–2025 window)\",\n",
        "    labels={\"contribution\": \"Contribution to change\"},\n",
        ")\n",
        "fig_contrib.show()\n"
      ],
      "metadata": {
        "id": "kqkBu_uC1UTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Vis 3: Where are the Jobs? (Business and Finance Sectors)\n",
        "\n",
        "Focus is on\n",
        "\n",
        "*   Employment growth (are payrolls expanding?)\n",
        "*   Earnings growth (are wages rising?)\n",
        "\n"
      ],
      "metadata": {
        "id": "YYK4CZkwTOBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select the right CES series IDs using metadata"
      ],
      "metadata": {
        "id": "0r_ysMlZTfvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pick_ces_series_id_contains(ce_series, must_have, data_type_code, prefer_sa=True):\n",
        "    s = ce_series.copy()\n",
        "    s[\"series_title\"] = s[\"series_title\"].astype(\"string\")\n",
        "    s[\"data_type_code\"] = s[\"data_type_code\"].astype(\"string\").str.strip()\n",
        "\n",
        "    m = s[s[\"data_type_code\"] == data_type_code]\n",
        "    for token in must_have:\n",
        "        m = m[m[\"series_title\"].str.contains(token, case=False, na=False)]\n",
        "\n",
        "    if m.empty:\n",
        "        raise KeyError(f\"No CES series match for tokens={must_have} and data_type_code='{data_type_code}'\")\n",
        "\n",
        "    if prefer_sa and \"seasonal\" in m.columns:\n",
        "        sa = m[m[\"seasonal\"].str.upper() == \"S\"]\n",
        "        if not sa.empty:\n",
        "            m = sa\n",
        "\n",
        "    return m.iloc[0][\"series_id\"]\n"
      ],
      "metadata": {
        "id": "_yBQ0ZLX86Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fin_emp_id  = pick_ces_series_id_contains(ce_series, [\"financial activities\", \"all employees\"], \"01\")\n",
        "fin_ahe_id  = pick_ces_series_id_contains(ce_series, [\"financial activities\", \"average hourly earnings\"], \"03\")\n",
        "\n",
        "pbs_emp_id  = pick_ces_series_id_contains(ce_series, [\"professional and business services\", \"all employees\"], \"01\")\n",
        "pbs_ahe_id  = pick_ces_series_id_contains(ce_series, [\"professional and business services\", \"average hourly earnings\"], \"03\")\n",
        "\n",
        "# Pull time series from the sector files you loaded\n",
        "fin_emp_ts  = series_ts(ce_fin_emp,  fin_emp_id,  \"emp\")\n",
        "fin_ahe_ts  = series_ts(ce_fin_ae,   fin_ahe_id,  \"ahe\")\n",
        "\n",
        "pbs_emp_ts  = series_ts(ce_pbs_emp,  pbs_emp_id,  \"emp\")\n",
        "pbs_ahe_ts  = series_ts(ce_pbs_ae,   pbs_ahe_id,  \"ahe\")\n"
      ],
      "metadata": {
        "id": "NfIXENZ29Dzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create yearly “snapshots” (2023, 2024, 2025)"
      ],
      "metadata": {
        "id": "LIs1I_fqTs2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def year_snapshot_row(industry: str, emp_ts: pd.DataFrame, ahe_ts: pd.DataFrame, year: int, month: int | None = 12):\n",
        "    e = emp_ts[[\"date\", \"emp\"]].copy()\n",
        "    w = ahe_ts[[\"date\", \"ahe\"]].copy()\n",
        "    both = e.merge(w, on=\"date\", how=\"inner\").sort_values(\"date\")\n",
        "\n",
        "    # try chosen month in that year (default Dec). If missing, fall back to latest month in that year.\n",
        "    in_year = both[both[\"date\"].dt.year == year]\n",
        "    if month is not None:\n",
        "        cand = in_year[in_year[\"date\"].dt.month == month]\n",
        "        snap_date = cand[\"date\"].max() if not cand.empty else in_year[\"date\"].max()\n",
        "    else:\n",
        "        snap_date = in_year[\"date\"].max()\n",
        "\n",
        "    if pd.isna(snap_date):\n",
        "        raise ValueError(f\"No overlapping emp/ahe data for {industry} in year {year}.\")\n",
        "\n",
        "    prev_date = (pd.Timestamp(snap_date) - pd.DateOffset(years=1)).to_period(\"M\")\n",
        "    both = both.set_index(both[\"date\"].dt.to_period(\"M\"))\n",
        "\n",
        "    if prev_date not in both.index:\n",
        "        raise ValueError(f\"Missing prior-year month needed for YoY: {snap_date:%Y-%m} for {industry}.\")\n",
        "\n",
        "    emp_curr = float(both.loc[pd.Timestamp(snap_date).to_period(\"M\"), \"emp\"])\n",
        "    ahe_curr = float(both.loc[pd.Timestamp(snap_date).to_period(\"M\"), \"ahe\"])\n",
        "    emp_prev = float(both.loc[prev_date, \"emp\"])\n",
        "    ahe_prev = float(both.loc[prev_date, \"ahe\"])\n",
        "\n",
        "    emp_yoy = (emp_curr / emp_prev - 1) * 100\n",
        "    ahe_yoy = (ahe_curr / ahe_prev - 1) * 100\n",
        "\n",
        "    return {\n",
        "        \"Year\": year,\n",
        "        \"Snapshot month\": pd.Timestamp(snap_date).strftime(\"%Y-%m\"),\n",
        "        \"Industry\": industry,\n",
        "        \"Employment (thousands)\": emp_curr,          # CES employment series are in thousands\n",
        "        \"Employment (people)\": emp_curr * 1000,\n",
        "        \"Avg hourly earnings ($)\": ahe_curr,\n",
        "        \"Employment YoY %\": emp_yoy,\n",
        "        \"Hourly earnings YoY %\": ahe_yoy,\n",
        "    }\n",
        "\n",
        "def build_year_outputs(year: int, sectors: list[tuple[str, pd.DataFrame, pd.DataFrame]], month: int | None = 12):\n",
        "    rows = [year_snapshot_row(name, emp_ts, ahe_ts, year=year, month=month) for name, emp_ts, ahe_ts in sectors]\n",
        "    table_df = pd.DataFrame(rows)\n",
        "\n",
        "    heatmap_df = (table_df[[\"Industry\", \"Employment YoY %\", \"Hourly earnings YoY %\"]]\n",
        "                  .set_index(\"Industry\")\n",
        "                  .round(2))\n",
        "\n",
        "    # format table\n",
        "    table_df[\"Employment (thousands)\"] = table_df[\"Employment (thousands)\"].round(2)\n",
        "    table_df[\"Employment (people)\"] = table_df[\"Employment (people)\"].round(0).astype(\"int64\")\n",
        "    table_df[\"Avg hourly earnings ($)\"] = table_df[\"Avg hourly earnings ($)\"].round(2)\n",
        "    table_df[\"Employment YoY %\"] = table_df[\"Employment YoY %\"].round(2)\n",
        "    table_df[\"Hourly earnings YoY %\"] = table_df[\"Hourly earnings YoY %\"].round(2)\n",
        "\n",
        "    return heatmap_df, table_df\n"
      ],
      "metadata": {
        "id": "caNS_Fi0t7Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heatmaps: side-by-side comparisons across years"
      ],
      "metadata": {
        "id": "I0WQcaZlTyVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sectors = [\n",
        "    (\"Financial activities\", fin_emp_ts, fin_ahe_ts),\n",
        "    (\"Professional & business services\", pbs_emp_ts, pbs_ahe_ts),\n",
        "]\n",
        "\n",
        "outputs = {}\n",
        "for y in [2025, 2024, 2023]:\n",
        "    hm_y, table_y = build_year_outputs(y, sectors, month=12)  # tries Dec; falls back to latest month in that year\n",
        "    outputs[y] = {\"hm\": hm_y, \"table\": table_y}\n",
        "\n",
        "    fig = px.imshow(\n",
        "        hm_y,\n",
        "        text_auto=\".2f\",\n",
        "        aspect=\"auto\",\n",
        "        title=f\"YoY % Snapshot — {y} (month used: {table_y['Snapshot month'].iloc[0]})\",\n",
        "        labels={\"color\": \"YoY %\", \"x\": \"Metric\", \"y\": \"Industry\"},\n",
        "    )\n",
        "\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# chronological order (oldest -> newest)\n",
        "years = [2023, 2024, 2025]\n",
        "\n",
        "# grab the heatmap dataframes you already built (index=Industry, columns=two YoY metrics)\n",
        "hms = {y: outputs[y][\"hm\"].copy() for y in years}\n",
        "\n",
        "# make sure all three share the same row order (union of industries, sorted)\n",
        "all_industries = sorted(set().union(*[hm.index.tolist() for hm in hms.values()]))\n",
        "\n",
        "# reindex so each subplot lines up row-by-row\n",
        "for y in years:\n",
        "    hms[y] = hms[y].reindex(all_industries)\n",
        "\n",
        "# global color scale so the colors are comparable across years\n",
        "vals = np.concatenate([hms[y].to_numpy().ravel() for y in years])\n",
        "vals = vals[np.isfinite(vals)]\n",
        "abs_max = float(np.nanmax(np.abs(vals))) if len(vals) else 1.0\n",
        "\n",
        "fig = make_subplots(\n",
        "    rows=1,\n",
        "    cols=3,\n",
        "    subplot_titles=[str(y) for y in years],\n",
        "    specs=[[{\"type\": \"heatmap\"}, {\"type\": \"heatmap\"}, {\"type\": \"heatmap\"}]],\n",
        "    horizontal_spacing=0.06\n",
        ")\n",
        "\n",
        "for i, y in enumerate(years, start=1):\n",
        "    z = hms[y].to_numpy()\n",
        "    x = list(hms[y].columns)\n",
        "    ylabels = list(hms[y].index)\n",
        "\n",
        "    fig.add_trace(\n",
        "        go.Heatmap(\n",
        "            z=z,\n",
        "            x=x,\n",
        "            y=ylabels,\n",
        "            text=np.round(z, 2),\n",
        "            texttemplate=\"%{text}\",\n",
        "            hovertemplate=\"Industry=%{y}<br>Metric=%{x}<br>YoY=%{z:.2f}%<extra></extra>\",\n",
        "            coloraxis=\"coloraxis\"  # shared colorscale across subplots\n",
        "        ),\n",
        "        row=1, col=i\n",
        "    )\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"CES YoY % by Industry — Side-by-side (2023 → 2025)\",\n",
        "    height=650,\n",
        "    # one shared colorbar/scale for all heatmaps\n",
        "    coloraxis=dict(cmin=-abs_max, cmax=abs_max, colorbar=dict(title=\"YoY %\")),\n",
        "    margin=dict(l=20, r=20, t=80, b=20),\n",
        ")\n",
        "\n",
        "# If the y-axis labels feel too dense, you can hide them on the middle/right panels:\n",
        "fig.update_yaxes(showticklabels=True, row=1, col=1)\n",
        "fig.update_yaxes(showticklabels=False, row=1, col=2)\n",
        "fig.update_yaxes(showticklabels=False, row=1, col=3)\n",
        "\n",
        "fig.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "arSKDrc85Zju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heat maps in tabular form"
      ],
      "metadata": {
        "id": "tYSWbCDrT0Wd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table_all = pd.concat([outputs[y][\"table\"] for y in [2025, 2024, 2023]], ignore_index=True)\n",
        "table_all = table_all.sort_values([\"Industry\", \"Year\"], ascending = [True, False]).reset_index(drop=True)\n",
        "table_all"
      ],
      "metadata": {
        "id": "pFDatyUi5k4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook Caveats with data:\n",
        "\n",
        "*  Missing October 2025 CPS data is a real BLS limitation, not a code bug.\n",
        "*   JOLTS “openings” are a month-end snapshot and require active recruiting + the job could start within 30 days.\n",
        "* CES employment in this setup is reported in thousands, so converting to “people” requires multiplying by 1,000\n",
        "\n"
      ],
      "metadata": {
        "id": "5p9HaB0NUHMz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V-Qp0jcmUddF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}